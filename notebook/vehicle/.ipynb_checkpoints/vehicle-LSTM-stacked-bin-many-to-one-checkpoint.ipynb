{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plot param\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (28.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the controller file\n",
    "f = open('../COTONN/vehicle_small/controller.scs', \"r\")\n",
    "\n",
    "lines = []\n",
    "\n",
    "for line in f:\n",
    "    if '#MATRIX:DATA\\n' in line:                \n",
    "        for line in f: # now you are at the lines you want\n",
    "            # skip the #BEGIN \n",
    "            # read the state-actions\n",
    "            lines = f.readlines()\n",
    "            \n",
    "del lines[-1]\n",
    "\n",
    "# take the state as the train dataset\n",
    "ltrain_dataset = []\n",
    "for x in lines:\n",
    "    ltrain_dataset.append(x.split(' ')[0])\n",
    "# del ltrain_dataset[-1] # delete the string #END at the end of the file \n",
    "\n",
    "# convert to the numpy array with float32 data type\n",
    "train_dataset = np.asarray(ltrain_dataset)\n",
    "train_dataset = train_dataset.astype(np.float32)\n",
    "\n",
    "upper_limit = train_dataset.shape[0]\n",
    "num_samples = upper_limit\n",
    "\n",
    "# take action/label pair of the state \n",
    "# take the action(s) [column 1:-1] / the rest of the integer except the state\n",
    "ltrain_label = []\n",
    "for x in lines:\n",
    "    if det == False:\n",
    "        ltrain_label.append(x.strip().split()[1:])\n",
    "    else:\n",
    "        ltrain_label.append(x.strip().split()[1])\n",
    "# del ltrain_label[-1] # delete the string #END at the end of the file  \n",
    "\n",
    "# convert to numpy array, note that the result is still not in one hot encoding format\n",
    "train_label = np.asarray(ltrain_label)\n",
    "\n",
    "# define number of samples\n",
    "# num_samples = train_dataset.shape[0]\n",
    "\n",
    "if det == False:\n",
    "    # select to use ND or D case here\n",
    "    # create now array to be filled by the encoded label\n",
    "    train_label_int = [[int(i) for i in l] for l in ltrain_label]\n",
    "    action_setlist = sorted(set(x for l in train_label_int for x in l))\n",
    "    num_label = len(action_setlist)\n",
    "    train_label_hot = np.zeros([num_samples, num_label], dtype=np.float32)\n",
    "    for i,actions in enumerate(train_label_int):\n",
    "        for action in actions:\n",
    "            train_label_hot[i, action_setlist.index(action)] = 1\n",
    "else:\n",
    "    train_label_hot = train_label[:, None].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48018,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48018, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dim = train_dataset[:, None]\n",
    "# slice the samples\n",
    "train_sliced = train_dataset_dim[:upper_limit]\n",
    "# change it to init\n",
    "train_sliced_int = train_sliced.astype(np.uint32)\n",
    "# split to 4 bytes\n",
    "tsi8_unordered = train_sliced_int.view(np.uint8)\n",
    "# little endian format\n",
    "tsi8 = np.flip(tsi8_unordered,1)\n",
    "# unpack\n",
    "toy_vehicle_input_unreduced = np.unpackbits(tsi8).reshape(-1,32)\n",
    "\n",
    "# get index of MSB\n",
    "msb = len(bin(int(np.max(train_dataset_dim))))-2\n",
    "# get total bit\n",
    "total_bit = toy_vehicle_input_unreduced.shape[1]\n",
    "# reduce to the minimal binary representation\n",
    "toy_vehicle_input = toy_vehicle_input_unreduced[:, np.arange(total_bit-msb,total_bit)]\n",
    "\n",
    "num_label = train_label_hot.shape[1]\n",
    "\n",
    "input_size = toy_vehicle_input.shape[1]\n",
    "\n",
    "train_dataset_reform = toy_vehicle_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of label\n",
    "num_label = len(set(train_label))\n",
    "lcoll_label = sorted((set(train_label)))\n",
    "\n",
    "# code to new ID\n",
    "train_label_transformed = np.zeros_like(train_label)\n",
    "for i in range(train_label.shape[0]):\n",
    "    train_label_transformed[i] = lcoll_label.index(train_label[i])\n",
    "    \n",
    "# convert to the one hot encoding representation\n",
    "train_label_hot = (np.arange(len(lcoll_label)) == train_label_transformed[:, None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (add dimension to the vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dim = train_dataset[:, None]\n",
    "\n",
    "# set the upper limit of experiment\n",
    "upper_limit = train_dataset_dim.shape[0] #40\n",
    "\n",
    "# slice the samples\n",
    "train_sliced = train_dataset_dim[:upper_limit]\n",
    "# convert to init\n",
    "train_sliced_int = train_sliced.astype(np.uint32)\n",
    "# split to 4 x uint8 representation (4 bytes of number) \n",
    "tsi8_unordered = train_sliced_int.view(np.uint8)\n",
    "# flip to make it on the little endian\n",
    "tsi8 = np.flip(tsi8_unordered,1)\n",
    "# unpack to 1 bit representation, total 32 bit\n",
    "toy_vehicle_input_unreduced = np.unpackbits(tsi8).reshape(-1,32)\n",
    "\n",
    "# get index of MSB\n",
    "msb = len(bin(int(np.max(train_dataset_dim))))-2\n",
    "# get total bit\n",
    "total_bit = toy_vehicle_input_unreduced.shape[1]\n",
    "# reduce to the minimal binary representation\n",
    "toy_vehicle_input = toy_vehicle_input_unreduced[:, np.arange(total_bit-msb,total_bit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dimenstion to vector (it becomes matrix)\n",
    "train_label_dim = train_label[:, None]\n",
    "# slice the samples\n",
    "train_label_sliced = train_label_dim[:upper_limit]\n",
    "# change it to int\n",
    "train_label_sliced_int = train_label_sliced.astype(np.uint32)\n",
    "# split to 4 bytes of number\n",
    "tsi8_label_unordered = train_label_sliced_int.view(np.uint8)\n",
    "# flip -> little endian format\n",
    "tsi8_label = np.flip(tsi8_label_unordered,1)\n",
    "\n",
    "# unpack the bit to 32 bit\n",
    "toy_vehicle_label_unreduced = np.unpackbits(tsi8_label).reshape(-1,32)\n",
    "\n",
    "# get index of MSB\n",
    "msb_label = len(bin(int(np.max(train_label_dim))))-2\n",
    "# get total bit\n",
    "total_bit = toy_vehicle_label_unreduced.shape[1]\n",
    "# reduce to the minimal binary representation\n",
    "toy_vehicle_label = toy_vehicle_label_unreduced[:, np.arange(total_bit-msb_label,total_bit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_softmax(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def accuracy_multilabel(predictions, labels):\n",
    "  return (100.0 * np.mean(predictions == labels))\n",
    "\n",
    "def accuracy_multilabel_softmax(predictions, labels):\n",
    "    predictions_soft = np.zeros_like(predictions)\n",
    "    predictions_soft[np.arange(len(predictions)), predictions.argmax(1)] = 1\n",
    "    return (100.0*np.mean(labels[np.arange(len(labels)), predictions_soft.argmax(1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 1024 # num_samples # (num_samples//20) # 113*6 # num_samples\n",
    "num_batches = np.ceil(num_samples/batch_size)\n",
    "state_size = 112\n",
    "input_LSTM_size = 1\n",
    "print(batch_size)\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "# tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size))\n",
    "# tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_label))\n",
    "tf_train_dataset = tf.placeholder(tf.float32, shape=(None, input_size))\n",
    "tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_label))\n",
    "dropout_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "cell_state = tf.placeholder(tf.float32, [None, state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [None, state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "Wout = tf.Variable(np.random.rand(state_size, num_label),dtype=tf.float32)\n",
    "bout = tf.Variable(np.zeros((1,num_label)), dtype=tf.float32)\n",
    "\n",
    "inputs_series = tf.split(tf_train_dataset, input_size, 1)\n",
    "\n",
    "from tensorflow.contrib import rnn \n",
    "cell = rnn.BasicLSTMCell(state_size)\n",
    "states_series, current_state = rnn.static_rnn(cell, inputs_series, init_state)\n",
    "logits = tf.matmul(states_series[-1], Wout) + bout\n",
    "predictions = tf.nn.softmax(logits)\n",
    "losses = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits,labels = tf_train_labels)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "# train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "train_step = tf.train.AdamOptimizer(0.0015).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-90f0964a028e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss_avg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 })\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[0mliveplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch:{0:6d}, Loss: {1:8.6f}, Accuracy:{2:6.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\livelossplot\\generic_plot.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m                   \u001b[0mmax_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                   \u001b[0mvalidation_fmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_fmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                   metric2title=self.metric2title)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\livelossplot\\core.py\u001b[0m in \u001b[0;36mdraw_plot\u001b[1;34m(logs, metrics, figsize, max_epoch, max_cols, validation_fmt, metric2title)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2261\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2262\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2263\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2264\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[1;32m--> 528\u001b[1;33m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[0;32m    529\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_dpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "acc_history = []\n",
    "liveplot = PlotLosses()\n",
    "\n",
    "acc = 0\n",
    "acc_cum = 0\n",
    "acc_temp = 0\n",
    "epoch_idx = 0\n",
    "loss_disp_true = False\n",
    "loss_avg = 0.0\n",
    "old_loss_avg = 0.0\n",
    "loss_cum = 0.0\n",
    "need_one_more_iteration = True\n",
    "\n",
    "early_stop_loss_counter = 0\n",
    "not_early_stop = True\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    while (((acc < 100) or need_one_more_iteration) and not_early_stop):\n",
    "        \n",
    "        if (acc >= 100):\n",
    "            need_one_more_iteration = False\n",
    "        else:\n",
    "            need_one_more_iteration = True\n",
    "            \n",
    "        epoch_idx += 1\n",
    "        acc_cum = 0\n",
    "        \n",
    "        for step in range(int(num_batches)):\n",
    "            offset = (step * batch_size)\n",
    "            if num_samples > offset + batch_size:\n",
    "                batch_limit = offset + batch_size\n",
    "            else:\n",
    "                batch_limit = num_samples\n",
    "                loss_disp_true = True\n",
    "\n",
    "            _current_cell_state = (np.zeros((batch_limit-offset, state_size)))\n",
    "            _current_hidden_state = (np.zeros((batch_limit-offset, state_size)))\n",
    "            batch_data = train_dataset_reform[offset:(batch_limit), :]\n",
    "            batch_labels = train_label_hot[offset:(batch_limit), :]\n",
    "\n",
    "            l , _train_step, _current_state, _predictions, = session.run(\n",
    "                [total_loss, train_step, current_state, predictions],\n",
    "                feed_dict={\n",
    "                    tf_train_dataset: batch_data,\n",
    "                    tf_train_labels: batch_labels,\n",
    "                    cell_state: _current_cell_state,\n",
    "                    hidden_state: _current_hidden_state\n",
    "                })\n",
    "            \n",
    "            # writer.add_summary(added_summary)\n",
    "            acc_temp =  accuracy_multilabel_softmax(_predictions, batch_labels)\n",
    "            acc_cum += acc_temp\n",
    "            acc = acc_cum/(step+1)\n",
    "            loss_cum += l\n",
    "            if loss_disp_true:\n",
    "                loss_disp_true = False\n",
    "                loss_avg = loss_cum/num_batches\n",
    "                loss_cum = 0\n",
    "                loss_history.append(loss_avg)\n",
    "                acc_history.append(acc)\n",
    "                liveplot.update({\n",
    "                    'accuracy': acc,\n",
    "                    'loss': loss_avg,\n",
    "                })\n",
    "                liveplot.draw()\n",
    "                print(\"Epoch:{0:6d}, Loss: {1:8.6f}, Accuracy:{2:6.2f}%\".format(epoch_idx, loss_avg, acc))\n",
    "                \n",
    "                if loss_avg == old_loss_avg:\n",
    "                    print('stagnan')\n",
    "                    early_stop_loss_counter += 1\n",
    "                    if early_stop_loss_counter == 100:\n",
    "                        not_early_stop = False    \n",
    "                old_loss_avg = loss_avg\n",
    "               \n",
    "    # Do for the test batch\n",
    "    acc = 0\n",
    "    acc_cum = 0\n",
    "    for step in range(int(num_batches)):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) #  % (train_label_hot.shape[0] - batch_size)\n",
    "        \n",
    "        if num_samples > offset + batch_size:\n",
    "            batch_limit = offset + batch_size\n",
    "        else:\n",
    "            batch_limit = num_samples\n",
    "            loss_disp_true = True\n",
    "\n",
    "        _current_cell_state = (np.zeros((batch_limit-offset, state_size)))\n",
    "        _current_hidden_state = (np.zeros((batch_limit-offset, state_size)))\n",
    "        # offset = np.random.randint(num_samples - batch_size , size = 1)[0]\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset_reform[offset:(batch_limit), :]\n",
    "        batch_labels = train_label_hot[offset:(batch_limit), :]\n",
    "\n",
    "        l, _current_state, _predictions, = session.run(\n",
    "            [total_loss, current_state, predictions],\n",
    "            feed_dict={\n",
    "                tf_train_dataset: batch_data,\n",
    "                tf_train_labels: batch_labels,\n",
    "                cell_state: _current_cell_state,\n",
    "                hidden_state: _current_hidden_state\n",
    "            })\n",
    "\n",
    "        # writer.add_summary(added_summary)\n",
    "        acc_temp =  accuracy_multilabel_softmax(_predictions, batch_labels)\n",
    "        acc_cum += acc_temp\n",
    "        acc = acc_cum/(step+1)\n",
    "        \n",
    "        print(\"batch_limit {0:6d} Training Acc: {1:8.2f} {2:8.2f} {3:8.2f}%\".format(batch_limit, acc_temp, acc_cum, acc))\n",
    "\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
