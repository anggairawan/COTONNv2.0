{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "LSTM on dcdc converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plot param\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (22.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, manipulate the input and output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the controller file\n",
    "f = open('../COTONN/dcdc_small_bdd/controller.scs', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the controller file\n",
    "f = open('controller.scs', \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the header part and go straight to the state-action pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in f:\n",
    "    if '#MATRIX:DATA\\n' in line:                \n",
    "        for line in f: # now you are at the lines you want\n",
    "            # skip the #BEGIN \n",
    "            # read the state-actions\n",
    "            lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the state as the train dataset\n",
    "ltrain_dataset = []\n",
    "for x in lines:\n",
    "    ltrain_dataset.append(x.split(' ')[0])\n",
    "# del ltrain_dataset[-1] # delete the string #END at the end of the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  113.,   114.,   115., ..., 40330., 40331., 40332.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to the numpy array with float32 data type\n",
    "train_dataset = np.asarray(ltrain_dataset)\n",
    "train_dataset = train_dataset.astype(np.float32)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the action(s) [column 1:-1] / the rest of the integer except the state\n",
    "ltrain_label = []\n",
    "for x in lines:\n",
    "    # ltrain_label.append(x.split(' ')[1:-1])\n",
    "    ltrain_label.append(x.split(' ')[1].strip('\\n'))\n",
    "# del ltrain_label[-1] # delete the string #END at the end of the file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '0', '0', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numpy array, note that the result is still not in one hot encoding format\n",
    "train_label = np.asarray(ltrain_label)\n",
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  113.,   114.,   115., ..., 40330., 40331., 40332.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37816"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of samples\n",
    "num_samples = train_dataset.shape[0]\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37816, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create now array to be filled by the encoded label\n",
    "train_label_hot = np.zeros([num_samples,2], dtype=np.float32)\n",
    "train_label_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode label to one hot encoding format\n",
    "for i in range(num_samples):\n",
    "    if train_label[i] == ['0']:\n",
    "        train_label_hot[i] = [1, 0]\n",
    "    elif train_label[i] == ['1']:\n",
    "        train_label_hot[i] = [0, 1]\n",
    "    elif train_label[i] == ['0','1']:\n",
    "        train_label_hot[i] = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_hot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dataset as mock up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the new number of samples for debugging purpose\n",
    "num_samples = 40\n",
    "# define batch offset to limit the desired dataset index\n",
    "batch_off = 20000+16800-87-25\n",
    "# slice the train label to the desired index\n",
    "train_label_hot = train_label_hot[batch_off:batch_off + num_samples]\n",
    "train_label_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same thing to the dataset and add dimension on the column\n",
    "train_dataset_reform = train_dataset[batch_off:batch_off + num_samples, None]\n",
    "train_dataset_reform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this to get the full batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37816, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the dimension of the dataset\n",
    "train_dataset_reform = train_dataset[:, None]\n",
    "train_dataset_reform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_reform[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40332.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_reform[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_hot[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_independent(predictions, labels):\n",
    "  return (100.0 * np.mean(np.asarray(predictions) == np.asarray(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMALL DATASET SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_series_length = num_samples\n",
    "state_size = 1\n",
    "num_classes = 2\n",
    "\n",
    "batch_size = 2\n",
    "truncated_backprop_length = 20\n",
    "\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_series_length = num_samples\n",
    "truncated_backprop_length = 193\n",
    "state_size = 1\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 7\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3073.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " num_samples/193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dataset_reform.reshape((batch_size,-1))\n",
    "y = train_label_hot.reshape((batch_size, -1, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length, num_classes])\n",
    "\n",
    "# init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "cell_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack columns\n",
    "inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:1' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:2' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:3' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:4' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:5' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:6' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:7' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:8' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:9' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:10' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:11' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:12' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:13' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:14' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:15' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:16' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:17' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:18' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'split:19' shape=(2, 1) dtype=float32>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:1' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:2' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:3' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:4' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:5' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:6' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:7' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:8' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:9' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:10' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:11' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:12' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:13' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:14' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:15' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:16' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:17' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:18' shape=(2, 2) dtype=float32>,\n",
       " <tf.Tensor 'unstack:19' shape=(2, 2) dtype=float32>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward passes\n",
    "# cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "# states_series, current_state = tf.nn.rnn(cell, inputs_series, init_state)\n",
    "# cell = tf.nn.rnn_cell.BasicLSTMCell(state_size, state_is_tuple=True)\n",
    "cell = rnn.BasicLSTMCell(state_size)\n",
    "# states_series, current_state = tf.nn.rnn(cell, inputs_series, init_state)\n",
    "states_series, current_state = rnn.static_rnn(cell, inputs_series, init_state)\n",
    "\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "# predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "predictions_series = [tf.round(tf.sigmoid(logits)) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sigmoid_cross_entropy_with_logits(logits = logits,labels = labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "# train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "train_step = tf.train.AdamOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=1, h=1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'Placeholder_2:0' shape=(2, 1) dtype=float32>, h=<tf.Tensor 'Placeholder_3:0' shape=(2, 1) dtype=float32>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnn/basic_lstm_cell/Mul_2:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_5:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_8:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_11:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_14:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_17:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_20:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_23:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_26:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_29:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_32:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_35:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_38:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_41:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_44:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_47:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_50:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_53:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_56:0' shape=(2, 1) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_lstm_cell/Mul_59:0' shape=(2, 1) dtype=float32>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/basic_lstm_cell/Add_39:0' shape=(2, 1) dtype=float32>, h=<tf.Tensor 'rnn/basic_lstm_cell/Mul_59:0' shape=(2, 1) dtype=float32>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20, 2)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step:      0 Loss: 0.8484 Training Acc: 31.25 %\n",
      "New data, epoch 1\n",
      "Step:      0 Loss: 0.7073 Training Acc: 46.25 %\n",
      "New data, epoch 2\n",
      "Step:      0 Loss: 0.6472 Training Acc: 68.75 %\n",
      "New data, epoch 3\n",
      "Step:      0 Loss: 0.6337 Training Acc: 68.75 %\n",
      "New data, epoch 4\n",
      "Step:      0 Loss: 0.6371 Training Acc: 68.75 %\n",
      "New data, epoch 5\n",
      "Step:      0 Loss: 0.6451 Training Acc: 68.75 %\n",
      "New data, epoch 6\n",
      "Step:      0 Loss: 0.6535 Training Acc: 68.75 %\n",
      "New data, epoch 7\n",
      "Step:      0 Loss: 0.6613 Training Acc: 68.75 %\n",
      "New data, epoch 8\n",
      "Step:      0 Loss: 0.6667 Training Acc: 68.75 %\n",
      "New data, epoch 9\n",
      "Step:      0 Loss: 0.6661 Training Acc: 68.75 %\n",
      "New data, epoch 10\n",
      "Step:      0 Loss: 0.6577 Training Acc: 68.75 %\n",
      "New data, epoch 11\n",
      "Step:      0 Loss: 0.6443 Training Acc: 68.75 %\n",
      "New data, epoch 12\n",
      "Step:      0 Loss: 0.6311 Training Acc: 68.75 %\n",
      "New data, epoch 13\n",
      "Step:      0 Loss: 0.6220 Training Acc: 68.75 %\n",
      "New data, epoch 14\n",
      "Step:      0 Loss: 0.6190 Training Acc: 68.75 %\n",
      "New data, epoch 15\n",
      "Step:      0 Loss: 0.6209 Training Acc: 68.75 %\n",
      "New data, epoch 16\n",
      "Step:      0 Loss: 0.6253 Training Acc: 68.75 %\n",
      "New data, epoch 17\n",
      "Step:      0 Loss: 0.6295 Training Acc: 68.75 %\n",
      "New data, epoch 18\n",
      "Step:      0 Loss: 0.6319 Training Acc: 68.75 %\n",
      "New data, epoch 19\n",
      "Step:      0 Loss: 0.6320 Training Acc: 68.75 %\n",
      "New data, epoch 20\n",
      "Step:      0 Loss: 0.6302 Training Acc: 68.75 %\n",
      "New data, epoch 21\n",
      "Step:      0 Loss: 0.6274 Training Acc: 68.75 %\n",
      "New data, epoch 22\n",
      "Step:      0 Loss: 0.6241 Training Acc: 68.75 %\n",
      "New data, epoch 23\n",
      "Step:      0 Loss: 0.6210 Training Acc: 68.75 %\n",
      "New data, epoch 24\n",
      "Step:      0 Loss: 0.6187 Training Acc: 68.75 %\n",
      "New data, epoch 25\n",
      "Step:      0 Loss: 0.6179 Training Acc: 68.75 %\n",
      "New data, epoch 26\n",
      "Step:      0 Loss: 0.6188 Training Acc: 68.75 %\n",
      "New data, epoch 27\n",
      "Step:      0 Loss: 0.6207 Training Acc: 68.75 %\n",
      "New data, epoch 28\n",
      "Step:      0 Loss: 0.6225 Training Acc: 68.75 %\n",
      "New data, epoch 29\n",
      "Step:      0 Loss: 0.6234 Training Acc: 68.75 %\n",
      "New data, epoch 30\n",
      "Step:      0 Loss: 0.6229 Training Acc: 68.75 %\n",
      "New data, epoch 31\n",
      "Step:      0 Loss: 0.6214 Training Acc: 68.75 %\n",
      "New data, epoch 32\n",
      "Step:      0 Loss: 0.6197 Training Acc: 68.75 %\n",
      "New data, epoch 33\n",
      "Step:      0 Loss: 0.6184 Training Acc: 68.75 %\n",
      "New data, epoch 34\n",
      "Step:      0 Loss: 0.6178 Training Acc: 68.75 %\n",
      "New data, epoch 35\n",
      "Step:      0 Loss: 0.6177 Training Acc: 68.75 %\n",
      "New data, epoch 36\n",
      "Step:      0 Loss: 0.6180 Training Acc: 68.75 %\n",
      "New data, epoch 37\n",
      "Step:      0 Loss: 0.6184 Training Acc: 68.75 %\n",
      "New data, epoch 38\n",
      "Step:      0 Loss: 0.6189 Training Acc: 68.75 %\n",
      "New data, epoch 39\n",
      "Step:      0 Loss: 0.6191 Training Acc: 68.75 %\n",
      "New data, epoch 40\n",
      "Step:      0 Loss: 0.6191 Training Acc: 68.75 %\n",
      "New data, epoch 41\n",
      "Step:      0 Loss: 0.6187 Training Acc: 68.75 %\n",
      "New data, epoch 42\n",
      "Step:      0 Loss: 0.6181 Training Acc: 68.75 %\n",
      "New data, epoch 43\n",
      "Step:      0 Loss: 0.6174 Training Acc: 68.75 %\n",
      "New data, epoch 44\n",
      "Step:      0 Loss: 0.6171 Training Acc: 68.75 %\n",
      "New data, epoch 45\n",
      "Step:      0 Loss: 0.6172 Training Acc: 68.75 %\n",
      "New data, epoch 46\n",
      "Step:      0 Loss: 0.6175 Training Acc: 68.75 %\n",
      "New data, epoch 47\n",
      "Step:      0 Loss: 0.6178 Training Acc: 68.75 %\n",
      "New data, epoch 48\n",
      "Step:      0 Loss: 0.6179 Training Acc: 68.75 %\n",
      "New data, epoch 49\n",
      "Step:      0 Loss: 0.6178 Training Acc: 68.75 %\n",
      "New data, epoch 50\n",
      "Step:      0 Loss: 0.6176 Training Acc: 68.75 %\n",
      "New data, epoch 51\n",
      "Step:      0 Loss: 0.6174 Training Acc: 68.75 %\n",
      "New data, epoch 52\n",
      "Step:      0 Loss: 0.6172 Training Acc: 68.75 %\n",
      "New data, epoch 53\n",
      "Step:      0 Loss: 0.6171 Training Acc: 68.75 %\n",
      "New data, epoch 54\n",
      "Step:      0 Loss: 0.6171 Training Acc: 68.75 %\n",
      "New data, epoch 55\n",
      "Step:      0 Loss: 0.6171 Training Acc: 68.75 %\n",
      "New data, epoch 56\n",
      "Step:      0 Loss: 0.6172 Training Acc: 68.75 %\n",
      "New data, epoch 57\n",
      "Step:      0 Loss: 0.6173 Training Acc: 68.75 %\n",
      "New data, epoch 58\n",
      "Step:      0 Loss: 0.6173 Training Acc: 68.75 %\n",
      "New data, epoch 59\n",
      "Step:      0 Loss: 0.6172 Training Acc: 68.75 %\n",
      "New data, epoch 60\n",
      "Step:      0 Loss: 0.6170 Training Acc: 68.75 %\n",
      "New data, epoch 61\n",
      "Step:      0 Loss: 0.6169 Training Acc: 68.75 %\n",
      "New data, epoch 62\n",
      "Step:      0 Loss: 0.6169 Training Acc: 68.75 %\n",
      "New data, epoch 63\n",
      "Step:      0 Loss: 0.6169 Training Acc: 68.75 %\n",
      "New data, epoch 64\n",
      "Step:      0 Loss: 0.6170 Training Acc: 68.75 %\n",
      "New data, epoch 65\n",
      "Step:      0 Loss: 0.6170 Training Acc: 68.75 %\n",
      "New data, epoch 66\n",
      "Step:      0 Loss: 0.6170 Training Acc: 68.75 %\n",
      "New data, epoch 67\n",
      "Step:      0 Loss: 0.6169 Training Acc: 68.75 %\n",
      "New data, epoch 68\n",
      "Step:      0 Loss: 0.6169 Training Acc: 68.75 %\n",
      "New data, epoch 69\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 70\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 71\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 72\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 73\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 74\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 75\n",
      "Step:      0 Loss: 0.6168 Training Acc: 68.75 %\n",
      "New data, epoch 76\n",
      "Step:      0 Loss: 0.6167 Training Acc: 68.75 %\n",
      "New data, epoch 77\n",
      "Step:      0 Loss: 0.6167 Training Acc: 68.75 %\n",
      "New data, epoch 78\n",
      "Step:      0 Loss: 0.6167 Training Acc: 68.75 %\n",
      "New data, epoch 79\n",
      "Step:      0 Loss: 0.6167 Training Acc: 68.75 %\n",
      "New data, epoch 80\n",
      "Step:      0 Loss: 0.6167 Training Acc: 68.75 %\n",
      "New data, epoch 81\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 82\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 83\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 84\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 85\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 86\n",
      "Step:      0 Loss: 0.6166 Training Acc: 68.75 %\n",
      "New data, epoch 87\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 88\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 89\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 90\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 91\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 92\n",
      "Step:      0 Loss: 0.6165 Training Acc: 68.75 %\n",
      "New data, epoch 93\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 94\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 95\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 96\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 97\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 98\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 99\n",
      "Step:      0 Loss: 0.6164 Training Acc: 68.75 %\n",
      "New data, epoch 100\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 101\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 102\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 103\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 104\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 105\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 106\n",
      "Step:      0 Loss: 0.6163 Training Acc: 68.75 %\n",
      "New data, epoch 107\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 108\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 109\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 110\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 111\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 112\n",
      "Step:      0 Loss: 0.6162 Training Acc: 68.75 %\n",
      "New data, epoch 113\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 114\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 115\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 116\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 117\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 118\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 119\n",
      "Step:      0 Loss: 0.6161 Training Acc: 68.75 %\n",
      "New data, epoch 120\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 121\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 122\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 123\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 124\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 125\n",
      "Step:      0 Loss: 0.6160 Training Acc: 68.75 %\n",
      "New data, epoch 126\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 127\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 128\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 129\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 130\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 131\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 132\n",
      "Step:      0 Loss: 0.6159 Training Acc: 68.75 %\n",
      "New data, epoch 133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 134\n",
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 135\n",
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 136\n",
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 137\n",
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 138\n",
      "Step:      0 Loss: 0.6158 Training Acc: 68.75 %\n",
      "New data, epoch 139\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 140\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 141\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 142\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 143\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 144\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 145\n",
      "Step:      0 Loss: 0.6157 Training Acc: 68.75 %\n",
      "New data, epoch 146\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 147\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 148\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 149\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 150\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 151\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 152\n",
      "Step:      0 Loss: 0.6156 Training Acc: 68.75 %\n",
      "New data, epoch 153\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 154\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 155\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 156\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 157\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 158\n",
      "Step:      0 Loss: 0.6155 Training Acc: 68.75 %\n",
      "New data, epoch 159\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 160\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 161\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 162\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 163\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 164\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 165\n",
      "Step:      0 Loss: 0.6154 Training Acc: 68.75 %\n",
      "New data, epoch 166\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 167\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 168\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 169\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 170\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 171\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 172\n",
      "Step:      0 Loss: 0.6153 Training Acc: 68.75 %\n",
      "New data, epoch 173\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 174\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 175\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 176\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 177\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 178\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 179\n",
      "Step:      0 Loss: 0.6152 Training Acc: 68.75 %\n",
      "New data, epoch 180\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 181\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 182\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 183\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 184\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 185\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 186\n",
      "Step:      0 Loss: 0.6151 Training Acc: 68.75 %\n",
      "New data, epoch 187\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 188\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 189\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 190\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 191\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 192\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 193\n",
      "Step:      0 Loss: 0.6150 Training Acc: 68.75 %\n",
      "New data, epoch 194\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 195\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 196\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 197\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 198\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 199\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 200\n",
      "Step:      0 Loss: 0.6149 Training Acc: 68.75 %\n",
      "New data, epoch 201\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 202\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 203\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 204\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 205\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 206\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 207\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 208\n",
      "Step:      0 Loss: 0.6148 Training Acc: 68.75 %\n",
      "New data, epoch 209\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 210\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 211\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 212\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 213\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 214\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 215\n",
      "Step:      0 Loss: 0.6147 Training Acc: 68.75 %\n",
      "New data, epoch 216\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 217\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 218\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 219\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 220\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 221\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 222\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 223\n",
      "Step:      0 Loss: 0.6146 Training Acc: 68.75 %\n",
      "New data, epoch 224\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 225\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 226\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 227\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 228\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 229\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 230\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 231\n",
      "Step:      0 Loss: 0.6145 Training Acc: 68.75 %\n",
      "New data, epoch 232\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 233\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 234\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 235\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 236\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 237\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 238\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 239\n",
      "Step:      0 Loss: 0.6144 Training Acc: 68.75 %\n",
      "New data, epoch 240\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 241\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 242\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 243\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 244\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 245\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 246\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 247\n",
      "Step:      0 Loss: 0.6143 Training Acc: 68.75 %\n",
      "New data, epoch 248\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 249\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 250\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 251\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 252\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 253\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 254\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 255\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 256\n",
      "Step:      0 Loss: 0.6142 Training Acc: 68.75 %\n",
      "New data, epoch 257\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 258\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 259\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 260\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 261\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 262\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 263\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 264\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 265\n",
      "Step:      0 Loss: 0.6141 Training Acc: 68.75 %\n",
      "New data, epoch 266\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 268\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 269\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 270\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 271\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 272\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 273\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 274\n",
      "Step:      0 Loss: 0.6140 Training Acc: 68.75 %\n",
      "New data, epoch 275\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 276\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 277\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 278\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 279\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 280\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 281\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 282\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 283\n",
      "Step:      0 Loss: 0.6139 Training Acc: 68.75 %\n",
      "New data, epoch 284\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 285\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 286\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 287\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 288\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 289\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 290\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 291\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 292\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 293\n",
      "Step:      0 Loss: 0.6138 Training Acc: 68.75 %\n",
      "New data, epoch 294\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 295\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 296\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 297\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 298\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 299\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 300\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 301\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 302\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 303\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 304\n",
      "Step:      0 Loss: 0.6137 Training Acc: 68.75 %\n",
      "New data, epoch 305\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 306\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 307\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 308\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 309\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 310\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 311\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 312\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 313\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 314\n",
      "Step:      0 Loss: 0.6136 Training Acc: 68.75 %\n",
      "New data, epoch 315\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 316\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 317\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 318\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 319\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 320\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 321\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 322\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 323\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 324\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 325\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 326\n",
      "Step:      0 Loss: 0.6135 Training Acc: 68.75 %\n",
      "New data, epoch 327\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 328\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 329\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 330\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 331\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 332\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 333\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 334\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 335\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 336\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 337\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 338\n",
      "Step:      0 Loss: 0.6134 Training Acc: 68.75 %\n",
      "New data, epoch 339\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 340\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 341\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 342\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 343\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 344\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 345\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 346\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 347\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 348\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 349\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 350\n",
      "Step:      0 Loss: 0.6133 Training Acc: 68.75 %\n",
      "New data, epoch 351\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 352\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 353\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 354\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 355\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 356\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 357\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 358\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 359\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 360\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 361\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 362\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 363\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 364\n",
      "Step:      0 Loss: 0.6132 Training Acc: 68.75 %\n",
      "New data, epoch 365\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 366\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 367\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 368\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 369\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 370\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 371\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 372\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 373\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 374\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 375\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 376\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 377\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 378\n",
      "Step:      0 Loss: 0.6131 Training Acc: 68.75 %\n",
      "New data, epoch 379\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 380\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 381\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 382\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 383\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 384\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 385\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 386\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 387\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 388\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 389\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 390\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 391\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 392\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 393\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 394\n",
      "Step:      0 Loss: 0.6130 Training Acc: 68.75 %\n",
      "New data, epoch 395\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 396\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 397\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 398\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 399\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 400\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 401\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 402\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 403\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 404\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 406\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 407\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 408\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 409\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 410\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 411\n",
      "Step:      0 Loss: 0.6129 Training Acc: 68.75 %\n",
      "New data, epoch 412\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 413\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 414\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 415\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 416\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 417\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 418\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 419\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 420\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 421\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 422\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 423\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 424\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 425\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 426\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 427\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 428\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 429\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 430\n",
      "Step:      0 Loss: 0.6128 Training Acc: 68.75 %\n",
      "New data, epoch 431\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 432\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 433\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 434\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 435\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 436\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 437\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 438\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 439\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 440\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 441\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 442\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 443\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 444\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 445\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 446\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 447\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 448\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 449\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 450\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 451\n",
      "Step:      0 Loss: 0.6127 Training Acc: 68.75 %\n",
      "New data, epoch 452\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 453\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 454\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 455\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 456\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 457\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 458\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 459\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 460\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 461\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 462\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 463\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 464\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 465\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 466\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 467\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 468\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 469\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 470\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 471\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 472\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 473\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 474\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 475\n",
      "Step:      0 Loss: 0.6126 Training Acc: 68.75 %\n",
      "New data, epoch 476\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 477\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 478\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 479\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 480\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 481\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 482\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 483\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 484\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 485\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 486\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 487\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 488\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 489\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 490\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 491\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 492\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 493\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 494\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 495\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 496\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 497\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 498\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 499\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 500\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 501\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 502\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 503\n",
      "Step:      0 Loss: 0.6125 Training Acc: 68.75 %\n",
      "New data, epoch 504\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 505\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 506\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 507\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 508\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 509\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 510\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 511\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 512\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 513\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 514\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 515\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 516\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 517\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 518\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 519\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 520\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 521\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 522\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 523\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 524\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 525\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 526\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 527\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 528\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 529\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 530\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 531\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 532\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 533\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 534\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 535\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 536\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 537\n",
      "Step:      0 Loss: 0.6124 Training Acc: 68.75 %\n",
      "New data, epoch 538\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 539\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 540\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 541\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 542\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 543\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 544\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 545\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 546\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 547\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 548\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 550\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 551\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 552\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 553\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 554\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 555\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 556\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 557\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 558\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 559\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 560\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 561\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 562\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 563\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 564\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 565\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 566\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 567\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 568\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 569\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 570\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 571\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 572\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 573\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 574\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 575\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 576\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 577\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 578\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 579\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 580\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 581\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 582\n",
      "Step:      0 Loss: 0.6123 Training Acc: 68.75 %\n",
      "New data, epoch 583\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 584\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 585\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 586\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 587\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 588\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 589\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 590\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 591\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 592\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 593\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 594\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 595\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 596\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 597\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 598\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 599\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 600\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 601\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 602\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 603\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 604\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 605\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 606\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 607\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 608\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 609\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 610\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 611\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 612\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 613\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 614\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 615\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 616\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 617\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 618\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 619\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 620\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 621\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 622\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 623\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 624\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 625\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 626\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 627\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 628\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 629\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 630\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 631\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 632\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 633\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 634\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 635\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 636\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 637\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 638\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 639\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 640\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 641\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 642\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 643\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 644\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 645\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 646\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 647\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 648\n",
      "Step:      0 Loss: 0.6122 Training Acc: 68.75 %\n",
      "New data, epoch 649\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 650\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 651\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 652\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 653\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 654\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 655\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 656\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 657\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 658\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 659\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 660\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 661\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 662\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 663\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 664\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 665\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 666\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 667\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 668\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 669\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 670\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 671\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 672\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 673\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 674\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 675\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 676\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 677\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 678\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 679\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 680\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 681\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 683\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 684\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 685\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 686\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 687\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 688\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 689\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 690\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 691\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 692\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 693\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 694\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 695\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 696\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 697\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 698\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 699\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 700\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 701\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 702\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 703\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 704\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 705\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 706\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 707\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 708\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 709\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 710\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 711\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 712\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 713\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 714\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 715\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 716\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 717\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 718\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 719\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 720\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 721\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 722\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 723\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 724\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 725\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 726\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 727\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 728\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 729\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 730\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 731\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 732\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 733\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 734\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 735\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 736\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 737\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 738\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 739\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 740\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 741\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 742\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 743\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 744\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 745\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 746\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 747\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 748\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 749\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 750\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 751\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 752\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 753\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 754\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 755\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 756\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 757\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 758\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 759\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 760\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 761\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 762\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 763\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 764\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 765\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 766\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 767\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 768\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 769\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 770\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 771\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 772\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 773\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 774\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 775\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 776\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 777\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 778\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 779\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 780\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 781\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 782\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 783\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 784\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 785\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 786\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 787\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 788\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 789\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 790\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 791\n",
      "Step:      0 Loss: 0.6121 Training Acc: 68.75 %\n",
      "New data, epoch 792\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 793\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 794\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 795\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 796\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 797\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 798\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 799\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 800\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 801\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 802\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 803\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 804\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 805\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 806\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 807\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 808\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 809\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 810\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 811\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 812\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 813\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 814\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 815\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 816\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 817\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 818\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 819\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 820\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 821\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 822\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 823\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 825\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 826\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 827\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 828\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 829\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 830\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 831\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 832\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 833\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 834\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 835\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 836\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 837\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 838\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 839\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 840\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 841\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 842\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 843\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 844\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 845\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 846\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 847\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 848\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 849\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 850\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 851\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 852\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 853\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 854\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 855\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 856\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 857\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 858\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 859\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 860\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 861\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 862\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 863\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 864\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 865\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 866\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 867\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 868\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 869\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 870\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 871\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 872\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 873\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 874\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 875\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 876\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 877\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 878\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 879\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 880\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 881\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 882\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 883\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 884\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 885\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 886\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 887\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 888\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 889\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 890\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 891\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 892\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 893\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 894\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 895\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 896\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 897\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 898\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 899\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 900\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 901\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 902\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 903\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 904\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 905\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 906\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 907\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 908\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 909\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 910\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 911\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 912\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 913\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 914\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 915\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 916\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 917\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 918\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 919\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 920\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 921\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 922\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 923\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 924\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 925\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 926\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 927\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 928\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 929\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 930\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 931\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 932\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 933\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 934\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 935\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 936\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 937\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 938\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 939\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 940\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 941\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 942\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 943\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 944\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 945\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 946\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 947\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 948\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 949\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 950\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 951\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 952\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 953\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 954\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 955\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 956\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 957\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 958\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 959\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 960\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 961\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 962\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 963\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 964\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 965\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 966\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 967\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 968\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 969\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 970\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 971\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 972\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 973\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 974\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 975\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 976\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 977\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 978\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 979\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 980\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 981\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 982\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 983\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 984\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 985\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 986\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 987\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 988\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 989\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 990\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 991\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 992\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 993\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 994\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 995\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 996\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 997\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 998\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "New data, epoch 999\n",
      "Step:      0 Loss: 0.6120 Training Acc: 68.75 %\n",
      "TESTING\n",
      "batch:     0 Accuracy: 68.75\n",
      "[array([[0., 0.],\n",
      "       [0., 0.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32)]\n",
      "[array([[0., 1.],\n",
      "       [1., 0.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 0.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 0.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 0.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 0.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[0., 1.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32), array([[1., 0.],\n",
      "       [1., 1.]], dtype=float32)]\n",
      "Accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.initialize_all_variables())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # plt.ion()\n",
    "    # plt.figure()\n",
    "    # plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(1000):\n",
    "        # x,y = generateData()\n",
    "        # _current_state = np.zeros((batch_size, state_size))\n",
    "        _current_cell_state = np.zeros((batch_size, state_size))\n",
    "        _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            \"\"\"\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "            \"\"\"\n",
    "            \n",
    "            _total_loss, _train_step, _current_state, _predictions_series, _labels_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series, labels_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    cell_state: _current_cell_state,\n",
    "                    hidden_state: _current_hidden_state\n",
    "                })\n",
    "            \n",
    "            _current_cell_state, _current_hidden_state = _current_state\n",
    "            \n",
    "            loss_list.append(_total_loss)\n",
    "            # print(_predictions_series)\n",
    "            # print(_labels_series)\n",
    "            \n",
    "            if batch_idx%100 == 0:\n",
    "                acc = accuracy_independent( _predictions_series, _labels_series)\n",
    "                print(\"Step: {0:6d} Loss: {1:.4f} Training Acc: {2:.2f} %\".format(batch_idx, _total_loss, acc))\n",
    "                # plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "    # accuracy\n",
    "    print(\"TESTING\")\n",
    "    # _current_state = np.zeros((batch_size, state_size))\n",
    "    _current_cell_state = np.zeros((batch_size, state_size))\n",
    "    _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "    acc = 0\n",
    "    total_acc = 0\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * truncated_backprop_length\n",
    "        end_idx = start_idx + truncated_backprop_length\n",
    "        \n",
    "        batchX = x[:,start_idx:end_idx]\n",
    "        batchY = y[:,start_idx:end_idx]\n",
    "        \n",
    "        _current_state, _predictions_series, _labels_series = sess.run(\n",
    "                [current_state, predictions_series, labels_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    cell_state: _current_cell_state,\n",
    "                    hidden_state: _current_hidden_state\n",
    "                })\n",
    "            \n",
    "        _current_cell_state, _current_hidden_state = _current_state\n",
    "            \n",
    "        acc = accuracy_independent( _predictions_series, _labels_series)\n",
    "        print(\"batch: {0:5d} Accuracy: {1:4.2f}\".format(batch_idx,acc))\n",
    "        total_acc += acc\n",
    "        print(_predictions_series)\n",
    "        print(_labels_series)\n",
    "    \n",
    "    print(\"Accuracy: {0:4.2f}%\".format(total_acc/num_batches))\n",
    "# plt.ioff()1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_predictions_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels_series"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
