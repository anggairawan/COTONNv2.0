{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plot param\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (22.0, 12.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the controller file\n",
    "f = open('../COTONN/dcdc_small/controller.scs', \"r\")\n",
    "\n",
    "lines = []\n",
    "\n",
    "for line in f:\n",
    "    if '#MATRIX:DATA\\n' in line:                \n",
    "        for line in f: # now you are at the lines you want\n",
    "            # skip the #BEGIN \n",
    "            # read the state-actions\n",
    "            lines = f.readlines()\n",
    "            \n",
    "del lines[-1]\n",
    "\n",
    "# take the state as the train dataset\n",
    "ltrain_dataset = []\n",
    "for x in lines:\n",
    "    ltrain_dataset.append(x.split(' ')[0])\n",
    "# del ltrain_dataset[-1] # delete the string #END at the end of the file \n",
    "\n",
    "# convert to the numpy array with float32 data type\n",
    "train_dataset = np.asarray(ltrain_dataset)\n",
    "train_dataset = train_dataset.astype(np.float32)\n",
    "\n",
    "upper_limit = train_dataset.shape[0]\n",
    "num_samples = upper_limit\n",
    "\n",
    "# take action/label pair of the state \n",
    "# take the action(s) [column 1:-1] / the rest of the integer except the state\n",
    "ltrain_label = []\n",
    "for x in lines:\n",
    "    if det == False:\n",
    "        ltrain_label.append(x.strip().split()[1:])\n",
    "    else:\n",
    "        ltrain_label.append(x.strip().split()[1])\n",
    "# del ltrain_label[-1] # delete the string #END at the end of the file  \n",
    "\n",
    "# convert to numpy array, note that the result is still not in one hot encoding format\n",
    "train_label = np.asarray(ltrain_label)\n",
    "\n",
    "# define number of samples\n",
    "# num_samples = train_dataset.shape[0]\n",
    "\n",
    "if det == False:\n",
    "    # select to use ND or D case here\n",
    "    # create now array to be filled by the encoded label\n",
    "    train_label_hot = np.zeros([num_samples,2], dtype=np.float32)\n",
    "\n",
    "    # encode label to one hot encoding format\n",
    "    for i in range(num_samples):\n",
    "        if train_label[i] == ['0']:\n",
    "            train_label_hot[i] = [1, 0]\n",
    "        elif train_label[i] == ['1']:\n",
    "            train_label_hot[i] = [0, 1]\n",
    "        elif train_label[i] == ['0','1']:\n",
    "            train_label_hot[i] = [1, 1]\n",
    "else:\n",
    "    train_label_hot = train_label[:, None].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(ltrain_label,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dim = train_dataset[:, None]\n",
    "# slice the samples\n",
    "train_sliced = train_dataset_dim[:upper_limit]\n",
    "# change it to init\n",
    "train_sliced_int = train_sliced.astype(np.uint32)\n",
    "# split to 4 bytes\n",
    "tsi8_unordered = train_sliced_int.view(np.uint8)\n",
    "# little endian format\n",
    "tsi8 = np.flip(tsi8_unordered,1)\n",
    "# unpack\n",
    "toy_vehicle_input_unreduced = np.unpackbits(tsi8).reshape(-1,32)\n",
    "\n",
    "# get index of MSB\n",
    "msb = len(bin(int(np.max(train_dataset_dim))))-2\n",
    "# get total bit\n",
    "total_bit = toy_vehicle_input_unreduced.shape[1]\n",
    "# reduce to the minimal binary representation\n",
    "toy_vehicle_input = toy_vehicle_input_unreduced[:, np.arange(total_bit-msb,total_bit)]\n",
    "\n",
    "num_label = train_label_hot.shape[1]\n",
    "\n",
    "input_size = toy_vehicle_input.shape[1]\n",
    "\n",
    "train_dataset_reform = toy_vehicle_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_reform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_softmax(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def accuracy_multilabel(predictions, labels):\n",
    "  return (100.0 * np.mean(predictions == labels))\n",
    "\n",
    "def accuracy_multilabel_softmax(predictions, labels):\n",
    "    predictions_soft = np.zeros_like(predictions)\n",
    "    predictions_soft[np.arange(len(predictions)), predictions.argmax(1)] = 1\n",
    "    return (100.0*np.mean(labels[np.arange(len(labels)), predictions_soft.argmax(1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 1024 #  num_samples # (num_samples//20) # 113*6 # num_samples\n",
    "num_batches = np.ceil(num_samples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "print(batch_size)\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_series_length = num_samples\n",
    "truncated_backprop_length = input_size\n",
    "state_size = 1\n",
    "input_rnn_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 x 15\n",
    "tf_train_dataset = tf.placeholder(tf.float32, [None, truncated_backprop_length])\n",
    "# 5 x 15\n",
    "tf_train_labels = tf.placeholder(tf.float32, [None, num_label])\n",
    "# initial state 5 x 4\n",
    "init_state = tf.placeholder(tf.float32, [None, state_size*num_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_2:0' shape=(?, 14) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wh1 = tf.Variable(np.random.rand(state_size+input_rnn_size, state_size), dtype=tf.float32)\n",
    "bh1 = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "Wh2 = tf.Variable(np.random.rand(state_size+input_rnn_size, state_size), dtype=tf.float32)\n",
    "bh2 = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "Wo = tf.Variable(np.random.rand(state_size*num_label, num_label),dtype=tf.float32)\n",
    "bo = tf.Variable(np.zeros((1,num_label)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack\n",
    "# Unpack columns/slice each column (5 x 15) -> (5x1) 15  \n",
    "inputs_series = tf.unstack(tf_train_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:1' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:2' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:3' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:4' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:5' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:6' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:7' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:8' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:9' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:10' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:11' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:12' shape=(?,) dtype=float32>,\n",
       " <tf.Tensor 'unstack:13' shape=(?,) dtype=float32>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "current_state = init_state # 5x4\n",
    "states_series = []\n",
    "for current_input in inputs_series:\n",
    "    # 5x1\n",
    "    current_input = tf.reshape(current_input, [-1, 1]) \n",
    "    # 5x1 concat 5x4 -> 5x5\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],1)  # Increasing number of columns\n",
    "    # 5x5, 5x4 -> 5x4 + 1x4 = 5x4\n",
    "    # next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "    next_state = tf.nn.sigmoid(tf.matmul(input_and_state_concatenated, Wh) + bh)  # Broadcasted addition\n",
    "    \n",
    "    states_series.append(next_state)\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5x4 * 4x2 + 1x2 = 5x2\n",
    "logits = tf.matmul(states_series[-1], Wo) + bo #Broadcasted addition\n",
    "train_predictions = tf.nn.softmax(logits)\n",
    "# compute the loss with cross entropy (it will be probabilistic 0-1 compare it with label)\n",
    "# losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits,labels = labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "losses = tf.nn.sigmoid_cross_entropy_with_logits(logits = logits,labels = tf_train_labels)\n",
    "# make the loss scalar\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "# gradient step\n",
    "train_step = tf.train.AdagradOptimizer(0.001).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_reform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_softmax(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def accuracy_multilabel(predictions, labels):\n",
    "  return (100.0 * np.mean(predictions == labels))\n",
    "\n",
    "def accuracy_multilabel_softmax(predictions, labels):\n",
    "    predictions_soft = np.zeros_like(predictions)\n",
    "    predictions_soft[np.arange(len(predictions)), predictions.argmax(1)] = 1\n",
    "    return (100.0*np.mean(labels[np.arange(len(labels)), predictions_soft.argmax(1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-db58050d51d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m                     \u001b[1;31m# 'val_mse': 1. / (i + 0.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 })\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mliveplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch:{0:6d}, Loss: {1:8.6f}, Accuracy:{2:6.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\livelossplot\\generic_plot.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m                   \u001b[0mmax_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                   \u001b[0mvalidation_fmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_fmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                   metric2title=self.metric2title)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\livelossplot\\core.py\u001b[0m in \u001b[0;36mdraw_plot\u001b[1;34m(logs, metrics, figsize, max_epoch, max_cols, validation_fmt, metric2title)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric2title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3816\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3817\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3818\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3819\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mlegend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'legend only accepts two non-keyword arguments'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlegend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'legend_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\legend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, handles, labels, loc, numpoints, markerscale, markerfirst, scatterpoints, scatteryoffsets, prop, fontsize, borderpad, labelspacing, handlelength, handleheight, handletextpad, borderaxespad, columnspacing, ncol, mode, fancybox, shadow, title, framealpha, edgecolor, facecolor, bbox_to_anchor, bbox_transform, frameon, handler_map)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;31m# init with null renderer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_legend_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkerfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# If shadow is activated use framealpha if not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\legend.py\u001b[0m in \u001b[0;36m_init_legend_box\u001b[1;34m(self, handles, labels, markerfirst)\u001b[0m\n\u001b[0;32m    944\u001b[0m                 textbox = TextArea(lab, textprops=label_prop,\n\u001b[0;32m    945\u001b[0m                                    \u001b[0mmultilinebaseline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m                                    minimumdescent=True)\n\u001b[0m\u001b[0;32m    947\u001b[0m                 handlebox = DrawingArea(width=self.handlelength * fontsize,\n\u001b[0;32m    948\u001b[0m                                         \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\offsetbox.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, s, textprops, multilinebaseline, minimumdescent)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_baseline_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         self._text.set_transform(self.offset_transform +\n",
      "\u001b[1;32mc:\\users\\gebruiker\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, tx, ty)\u001b[0m\n\u001b[0;32m   2070\u001b[0m         translate_mtx = np.array(\n\u001b[0;32m   2071\u001b[0m             [[1.0, 0.0, tx], [0.0, 1.0, ty], [0.0, 0.0, 1.0]], float)\n\u001b[1;32m-> 2072\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2073\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "liveplot = PlotLosses()\n",
    "\n",
    "acc = 0\n",
    "acc_cum = 0\n",
    "acc_temp = 0\n",
    "epoch_idx = 0\n",
    "loss_disp_true = False\n",
    "loss_avg = 0.0\n",
    "old_loss_avg = 0.0\n",
    "loss_cum = 0.0\n",
    "need_one_more_iteration = True\n",
    "\n",
    "early_stop_loss_counter = 0\n",
    "not_early_stop = True\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Initialized\")\n",
    "    while ((acc < 100) or need_one_more_iteration) and not_early_stop:\n",
    "        if (acc >= 100):\n",
    "            need_one_more_iteration = False\n",
    "            \n",
    "        epoch_idx += 1\n",
    "        acc_cum = 0\n",
    "        for step in range(int(num_batches)):\n",
    "            offset = (step * batch_size)\n",
    "            if num_samples > offset + batch_size:\n",
    "                batch_limit = offset + batch_size\n",
    "            else:\n",
    "                batch_limit = num_samples\n",
    "                loss_disp_true = True\n",
    "                \n",
    "            _current_state = np.zeros((batch_limit-offset, state_size))\n",
    "            batch_data = train_dataset_reform[offset:(batch_limit), :]\n",
    "            batch_labels = train_label_hot[offset:(batch_limit), :]\n",
    "            \n",
    "            # calculate loss, gradient step, \n",
    "            l, _train_step, _current_state, predictions = sess.run(\n",
    "                [total_loss, train_step, current_state, train_predictions],\n",
    "                feed_dict={\n",
    "                    tf_train_dataset:batch_data,\n",
    "                    tf_train_labels:batch_labels,\n",
    "                    # it was part of computational graph, where the init_state is the placeholder\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "            \n",
    "            acc_temp =  accuracy_multilabel_softmax(predictions, batch_labels)\n",
    "            acc_cum += acc_temp\n",
    "            acc = acc_cum/(step+1)\n",
    "            loss_cum += l\n",
    "            if loss_disp_true:\n",
    "                loss_disp_true = False\n",
    "                loss_avg = loss_cum/num_batches\n",
    "                loss_cum = 0\n",
    "                loss_history.append(loss_avg)\n",
    "                acc_history.append(acc)\n",
    "                liveplot.update({\n",
    "                    'accuracy': acc,\n",
    "                    # 'val_accuracy': 1 - np.random.rand() / (i + 0.5),\n",
    "                    'loss': loss_avg,\n",
    "                    # 'val_mse': 1. / (i + 0.5)\n",
    "                })\n",
    "                liveplot.draw()\n",
    "                print(\"Epoch:{0:6d}, Loss: {1:8.6f}, Accuracy:{2:6.2f}%\".format(epoch_idx, loss_avg, acc))\n",
    "                \n",
    "                if loss_avg == old_loss_avg:\n",
    "                    print('stagnan')\n",
    "                    early_stop_loss_counter += 1\n",
    "                    if early_stop_loss_counter == 100:\n",
    "                        not_early_stop = False\n",
    "                    \n",
    "                old_loss_avg = loss_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    # accuracy\n",
    "    _current_state = np.zeros((batch_size, state_size))\n",
    "    acc = 0\n",
    "    total_acc = 0\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * truncated_backprop_length\n",
    "        end_idx = start_idx + truncated_backprop_length\n",
    "        \n",
    "        batchX = x[:,start_idx:end_idx]\n",
    "        batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "        # calculate loss, gradient step, \n",
    "        _predictions_series, _labels_series = sess.run([predictions_series, labels_series],\n",
    "            feed_dict={\n",
    "                batchX_placeholder:batchX,\n",
    "                batchY_placeholder:batchY,\n",
    "                # it was part of computational graph, where the init_state is the placeholder\n",
    "                init_state:_current_state\n",
    "            })\n",
    "        acc = accuracy_independent( _predictions_series, _labels_series)\n",
    "        print(\"batch:\",batch_idx,\", accuracy:\",acc)\n",
    "        total_acc += acc\n",
    "    \n",
    "    print(total_acc/num_batches)\n",
    "# plt.ioff()\n",
    "# plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
